# Выводы по результатам `solution.ipynb`

1. **LSTM‑модель.** Обучение прошло 10 эпох на GPU. Метрики ROUGE низкие и
   стагнируют: ROUGE‑1 колеблется около `0.10–0.114`, ROUGE‑2 около
   `0.008–0.015` (лучшие значения: ROUGE‑1 ≈ 0.1136 на 5‑й эпохе,
   ROUGE‑2 ≈ 0.0145 на 8‑й).
2. **Transformer (distilgpt2).** Метрики ROUGE на 917 примерах: **ROUGE-1: 0.0720 | ROUGE-2: 0.0125**.
   Результаты ниже, чем у LSTM по ROUGE-1, но сопоставимы по ROUGE-2.
3. LSTM показывает лучшие результаты по ROUGE-1 (0.1136 vs 0.0720), что указывает на лучшее
   совпадение отдельных слов. По ROUGE-2 результаты близки (0.0145 vs 0.0125).

Качественный анализ генераций:
   - LSTM часто генерирует последовательности с множеством `<unk>` токенов
     (примеры 2, 4, 5, 12, 13, 16). В редких случаях генерирует осмысленные продолжения
     (пример 19: "just got home. about to go for a walk with my").
   - distilgpt2: генерирует более правильный текст без `<unk>`,
     но часто даёт пустые или очень короткие продолжения (примеры 1, 8, 11).
     Продолжения семантически не всегда соответствуют контексту, но выглядят
     естественно (пример 3: "much the only thing i have" вместо "area for
     flying, but very expensive").
   - Обе модели редко точно предсказывают истинное
     продолжение, что согласуется с низкими метриками ROUGE. 
     distilgpt2 демонстрирует лучшую корректность, но LSTM иногда лучше улавливает семантику.