## Автодополнение текста: LSTM и Transformer

Проект для сравнения простого LSTM‑подхода и предобученного трансформера (`distilgpt2`)
в задаче автодополнения текста. В качестве качества используется метрика **ROUGE**,
а данные берутся из датасета **Sentiment140**, сохранённого в `data/raw_dataset.txt`.

### Структура проекта

- **`solution.ipynb`** — основной ноутбук:
  - подготавливает датасет (train / val / test);
  - обучает LSTM‑модель автодополнения и считает ROUGE;
  - оценивает `distilgpt2` и считает ROUGE + выводит примеры предсказаний.
- **`src/data_utils.py`** — очистка текста и разбиение на train / val / test.
- **`src/next_token_dataset.py`** — датасет для предсказания следующего токена + построение словаря.
- **`src/lstm_model.py`** — реализация простой LSTM‑модели автодополнения.
- **`src/lstm_train.py`** — обучение LSTM, расчёт ROUGE и сохранение модели.
- **`src/eval_lstm.py`** — функция `compute_rouge` (обёртка над `evaluate`).
- **`src/eval_transformer_pipeline.py`** — оценка `distilgpt2` на валидации, расчёт ROUGE и вывод примеров.
- **`src/test.py`** — интерактивное тестирование обученной LSTM‑модели (ручной ввод фразы).

### Установка окружения

1. Создайте и активируйте виртуальное окружение (пример для Windows + PowerShell):

```powershell
python -m venv env
.\env\Scripts\activate
```

2. Установите зависимости:

```powershell
pip install -r requirements.txt
```

> При наличии GPU рекомендуется установить сборку PyTorch с поддержкой CUDA
> согласно инструкции на сайте `pytorch.org`.

### Подготовка данных

В папке `data` должен лежать файл **`raw_dataset.txt`** с текстами из **Sentiment140**.  
Формат: по одной строке на пример (сообщение/фраза). Внутри ноутбука данные будут
очищены и токенизированы.

### Как запускать пайплайн (через ноутбук)

1. Откройте `solution.ipynb` в Jupyter / VS Code / другой IDE.
2. Последовательно выполните ячейки:
   - **Ячейка 1** — описание (markdown).
   - **Ячейка 2** — подготовка датасета:
     - читает `data/raw_dataset.txt`;
     - сохраняет `train_tokens.txt`, `val_tokens.txt`, `test_tokens.txt`.
   - **Ячейка 3** — обучение LSTM:
     - обучает модель на `train_tokens.txt`;
     - считает ROUGE на валидации;
     - сохраняет модель в `models/lstm_autocomplete.pt`.
   - **Ячейка 4** — оценка трансформера:
     - запускает `distilgpt2` на валидационных предложениях;
     - считает ROUGE;
     - выводит несколько примеров предсказаний.

### Как отдельно протестировать обученную LSTM‑модель

После обучения (или если модель уже сохранена в `models/lstm_autocomplete.pt`) можно
запустить интерактивное тестирование:

```bash
python src/test.py
```

Скрипт загрузит сохранённую модель, предложит ввести начальную фразу
и выведет сгенерированное продолжение.

### Как отдельно запустить оценку трансформера

Если датасет уже подготовлен (`data/val_tokens.txt` существует), можно
запустить только оценку `distilgpt2`:

```bash
python src/eval_transformer_pipeline.py
```

Будут выведены значения ROUGE и несколько примеров автодополнений.

### Требования

- Python 3.11+
- PyTorch (CPU или CUDA‑сборка)
- `transformers`, `evaluate`, `rouge_score` и прочие зависимости из `requirements.txt`
